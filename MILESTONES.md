# Milestones

- [x] chat with llms local (console)
- [ ] add loaders support (gtp4all, llama.cpp, gptq etc)
- [ ] add embeddings support (chroma)
- [ ] see if it is necessary to add alternatives to chroma
- [ ] chat with llms local (webui)
- [ ] add embeddings support (webui)


# Todo
- [ ] use json files for loading models
- [ ] add arguments to choice json files to load
- [ ] add arguments to choice chat type (console, web)
- [ ] check if automatic tests are necessary
